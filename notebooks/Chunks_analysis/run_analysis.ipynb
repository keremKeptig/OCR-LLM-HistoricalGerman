{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from src.llms_ocr.errors_calculator_chunks import ErrorsCalculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb2242c",
   "metadata": {},
   "source": [
    "#### Load the model\n",
    "\n",
    "Can be replaced with any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lama_model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "lama_tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482446d5",
   "metadata": {},
   "source": [
    "#### Load the data\n",
    "\n",
    "Set the input directory with xml files and output directory for storing the results either as json or csv files.\n",
    "The output file contains the list of words for given page with following information:\n",
    "`word,line_id,paragraph_id,word_position,perplexity,is_error,page_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5575b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../../data/d2_0001-0100_without_marginalia\")\n",
    "out_dir = Path(\"../../data/json_csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8e89f",
   "metadata": {},
   "source": [
    "#### Run analysis\n",
    "\n",
    "Iterate over all xml files, process the page and save results in json and/or csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3180f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xml_file in data_dir.glob(\"*.xml\"):\n",
    "    page_base = xml_file.stem\n",
    "    json_file = out_dir / f\"{page_base}.json\"\n",
    "    csv_file = out_dir / f\"{page_base}.csv\"\n",
    "    if json_file.exists() and csv_file.exists():\n",
    "        print(f\"Skipping {xml_file.name} because results already exist.\")\n",
    "        continue\n",
    "    # Initialize the Score Calculator\n",
    "    # chunk_size and overlap_size can be adjusted\n",
    "    calculator = ErrorsCalculator(\n",
    "        model=lama_model, tokenizer=lama_tokenizer, chunk_size=20, overlap_size=10\n",
    "    )\n",
    "    try:\n",
    "        json_data, frame = calculator.process_page(Path(xml_file))\n",
    "        # save the results as json\n",
    "        calculator.save_json(\n",
    "            data=json_data,\n",
    "            out_dir=out_dir,\n",
    "            file_name=f\"{xml_file.stem}.json\",\n",
    "        )\n",
    "        # save the results as csv\n",
    "        calculator.save_dataframe(\n",
    "            df=frame,\n",
    "            out_dir=out_dir,\n",
    "            file_name=f\"{xml_file.stem}.csv\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {xml_file}: {e}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
